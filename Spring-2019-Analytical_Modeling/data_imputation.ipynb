{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 HW\n",
    "## Question 14.1\n",
    "The breast cancer data set breast-cancer-wisconsin.data.txt has missing values.\n",
    "1. Use the mean/mode imputation method to impute values for the missing data.\n",
    "2. Use regression to impute values for the missing data.\n",
    "3. Use regression with perturbation to impute values for the missing data.\n",
    "4. (Optional) Compare the results and quality of classification models (e.g., SVM, KNN) build using\n",
    "(1) the data sets from questions 1,2,3;\n",
    "(2) the data that remains after data points with missing values are removed; and\n",
    "(3) the data set when a binary variable is introduced to indicate missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Part 1\n",
    "In the first part of question 14.1, I am going to use the mean/mode imputation method to impute values for the missing data. In the first step below, I did some basic set up and viewed the data we're working with. From the explanation on the website hosting this dataset, the mising values are stored in the column bare_nuclei. I renamed all of the columns to match the explanation, and then stored the missing data points of which there are 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>V11</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1000025</td><td>5      </td><td> 1     </td><td> 1     </td><td>1      </td><td>2      </td><td>1      </td><td>3      </td><td>1      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1002945</td><td>5      </td><td> 4     </td><td> 4     </td><td>5      </td><td>7      </td><td>10     </td><td>3      </td><td>2      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1015425</td><td>3      </td><td> 1     </td><td> 1     </td><td>1      </td><td>2      </td><td>2      </td><td>3      </td><td>1      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1016277</td><td>6      </td><td> 8     </td><td> 8     </td><td>1      </td><td>3      </td><td>4      </td><td>3      </td><td>7      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1017023</td><td>4      </td><td> 1     </td><td> 1     </td><td>3      </td><td>2      </td><td>1      </td><td>3      </td><td>1      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1017122</td><td>8      </td><td>10     </td><td>10     </td><td>8      </td><td>7      </td><td>10     </td><td>9      </td><td>7      </td><td>1      </td><td>4      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & V11\\\\\n",
       "\\hline\n",
       "\t 1000025 & 5       &  1      &  1      & 1       & 2       & 1       & 3       & 1       & 1       & 2      \\\\\n",
       "\t 1002945 & 5       &  4      &  4      & 5       & 7       & 10      & 3       & 2       & 1       & 2      \\\\\n",
       "\t 1015425 & 3       &  1      &  1      & 1       & 2       & 2       & 3       & 1       & 1       & 2      \\\\\n",
       "\t 1016277 & 6       &  8      &  8      & 1       & 3       & 4       & 3       & 7       & 1       & 2      \\\\\n",
       "\t 1017023 & 4       &  1      &  1      & 3       & 2       & 1       & 3       & 1       & 1       & 2      \\\\\n",
       "\t 1017122 & 8       & 10      & 10      & 8       & 7       & 10      & 9       & 7       & 1       & 4      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | V11 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1000025 | 5       |  1      |  1      | 1       | 2       | 1       | 3       | 1       | 1       | 2       |\n",
       "| 1002945 | 5       |  4      |  4      | 5       | 7       | 10      | 3       | 2       | 1       | 2       |\n",
       "| 1015425 | 3       |  1      |  1      | 1       | 2       | 2       | 3       | 1       | 1       | 2       |\n",
       "| 1016277 | 6       |  8      |  8      | 1       | 3       | 4       | 3       | 7       | 1       | 2       |\n",
       "| 1017023 | 4       |  1      |  1      | 3       | 2       | 1       | 3       | 1       | 1       | 2       |\n",
       "| 1017122 | 8       | 10      | 10      | 8       | 7       | 10      | 9       | 7       | 1       | 4       |\n",
       "\n"
      ],
      "text/plain": [
       "  V1      V2 V3 V4 V5 V6 V7 V8 V9 V10 V11\n",
       "1 1000025 5   1  1 1  2  1  3  1  1   2  \n",
       "2 1002945 5   4  4 5  7  10 3  2  1   2  \n",
       "3 1015425 3   1  1 1  2  2  3  1  1   2  \n",
       "4 1016277 6   8  8 1  3  4  3  7  1   2  \n",
       "5 1017023 4   1  1 3  2  1  3  1  1   2  \n",
       "6 1017122 8  10 10 8  7  10 9  7  1   4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "suppressWarnings(library(tidyr))\n",
    "suppressWarnings(library(dplyr))\n",
    "\n",
    "# Read and view the data\n",
    "df <- tbl_df(read.table('breast-cancer-wisconsin.data.txt', sep=\",\"))\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>code_number</th><th scope=col>clump_thickness</th><th scope=col>cell_size_uniformity</th><th scope=col>cell_shape_uniformity</th><th scope=col>marginal_adhesion</th><th scope=col>single_epithelial_cell_size</th><th scope=col>bare_nuclei</th><th scope=col>bland_chromatin</th><th scope=col>normal_nucleoli</th><th scope=col>mitosis</th><th scope=col>class</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1057013</td><td>8      </td><td>4      </td><td>5      </td><td>1      </td><td>2      </td><td>?      </td><td>7      </td><td>3      </td><td>1      </td><td>4      </td></tr>\n",
       "\t<tr><td>1096800</td><td>6      </td><td>6      </td><td>6      </td><td>9      </td><td>6      </td><td>?      </td><td>7      </td><td>8      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1183246</td><td>1      </td><td>1      </td><td>1      </td><td>1      </td><td>1      </td><td>?      </td><td>2      </td><td>1      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1184840</td><td>1      </td><td>1      </td><td>3      </td><td>1      </td><td>2      </td><td>?      </td><td>2      </td><td>1      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1193683</td><td>1      </td><td>1      </td><td>2      </td><td>1      </td><td>3      </td><td>?      </td><td>1      </td><td>1      </td><td>1      </td><td>2      </td></tr>\n",
       "\t<tr><td>1197510</td><td>5      </td><td>1      </td><td>1      </td><td>1      </td><td>2      </td><td>?      </td><td>3      </td><td>1      </td><td>1      </td><td>2      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " code\\_number & clump\\_thickness & cell\\_size\\_uniformity & cell\\_shape\\_uniformity & marginal\\_adhesion & single\\_epithelial\\_cell\\_size & bare\\_nuclei & bland\\_chromatin & normal\\_nucleoli & mitosis & class\\\\\n",
       "\\hline\n",
       "\t 1057013 & 8       & 4       & 5       & 1       & 2       & ?       & 7       & 3       & 1       & 4      \\\\\n",
       "\t 1096800 & 6       & 6       & 6       & 9       & 6       & ?       & 7       & 8       & 1       & 2      \\\\\n",
       "\t 1183246 & 1       & 1       & 1       & 1       & 1       & ?       & 2       & 1       & 1       & 2      \\\\\n",
       "\t 1184840 & 1       & 1       & 3       & 1       & 2       & ?       & 2       & 1       & 1       & 2      \\\\\n",
       "\t 1193683 & 1       & 1       & 2       & 1       & 3       & ?       & 1       & 1       & 1       & 2      \\\\\n",
       "\t 1197510 & 5       & 1       & 1       & 1       & 2       & ?       & 3       & 1       & 1       & 2      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| code_number | clump_thickness | cell_size_uniformity | cell_shape_uniformity | marginal_adhesion | single_epithelial_cell_size | bare_nuclei | bland_chromatin | normal_nucleoli | mitosis | class |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1057013 | 8       | 4       | 5       | 1       | 2       | ?       | 7       | 3       | 1       | 4       |\n",
       "| 1096800 | 6       | 6       | 6       | 9       | 6       | ?       | 7       | 8       | 1       | 2       |\n",
       "| 1183246 | 1       | 1       | 1       | 1       | 1       | ?       | 2       | 1       | 1       | 2       |\n",
       "| 1184840 | 1       | 1       | 3       | 1       | 2       | ?       | 2       | 1       | 1       | 2       |\n",
       "| 1193683 | 1       | 1       | 2       | 1       | 3       | ?       | 1       | 1       | 1       | 2       |\n",
       "| 1197510 | 5       | 1       | 1       | 1       | 2       | ?       | 3       | 1       | 1       | 2       |\n",
       "\n"
      ],
      "text/plain": [
       "  code_number clump_thickness cell_size_uniformity cell_shape_uniformity\n",
       "1 1057013     8               4                    5                    \n",
       "2 1096800     6               6                    6                    \n",
       "3 1183246     1               1                    1                    \n",
       "4 1184840     1               1                    3                    \n",
       "5 1193683     1               1                    2                    \n",
       "6 1197510     5               1                    1                    \n",
       "  marginal_adhesion single_epithelial_cell_size bare_nuclei bland_chromatin\n",
       "1 1                 2                           ?           7              \n",
       "2 9                 6                           ?           7              \n",
       "3 1                 1                           ?           2              \n",
       "4 1                 2                           ?           2              \n",
       "5 1                 3                           ?           1              \n",
       "6 1                 2                           ?           3              \n",
       "  normal_nucleoli mitosis class\n",
       "1 3               1       4    \n",
       "2 8               1       2    \n",
       "3 1               1       2    \n",
       "4 1               1       2    \n",
       "5 1               1       2    \n",
       "6 1               1       2    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename columns from data explanation\n",
    "df <- df %>%\n",
    "    rename(code_number = V1,\n",
    "    clump_thickness = V2,\n",
    "    cell_size_uniformity = V3,\n",
    "    cell_shape_uniformity = V4,\n",
    "    marginal_adhesion = V5,\n",
    "    single_epithelial_cell_size = V6,\n",
    "    bare_nuclei = V7,\n",
    "    bland_chromatin = V8,\n",
    "    normal_nucleoli = V9,\n",
    "    mitosis = V10,\n",
    "    class = V11)\n",
    "\n",
    "# Get missing value count\n",
    "missing_df <- df %>%\n",
    "    filter(bare_nuclei == '?')\n",
    "\n",
    "nrow(missing_df)\n",
    "head(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step I am going to implement the mean/mode imputation method. This method takes the mean or mode of the non-missing data, and inputs that for the missing data. The code block directly below executes this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.21669106881406"
      ],
      "text/latex": [
       "3.21669106881406"
      ],
      "text/markdown": [
       "3.21669106881406"
      ],
      "text/plain": [
       "[1] 3.216691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Capture non-missing data\n",
    "bare_nuclei_mean <- df %>%\n",
    "    filter(bare_nuclei != '?') %>%\n",
    "    select(bare_nuclei) \n",
    "\n",
    "# Calculate and store mean of non-missing data\n",
    "bare_nuclei_mean <- mean(as.integer(bare_nuclei_mean$bare_nuclei))\n",
    "\n",
    "# Print captured mean\n",
    "bare_nuclei_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copy original data set for modification\n",
    "imputed_df_mean <- df\n",
    "\n",
    "# Convert bare nuclei to string\n",
    "imputed_df_mean$bare_nuclei <- as.character(imputed_df_mean$bare_nuclei)\n",
    "\n",
    "# Replace missing values with mean calculated above\n",
    "imputed_df_mean$bare_nuclei[imputed_df_mean$bare_nuclei == '?'] <- as.character(bare_nuclei_mean)\n",
    "imputed_df_mean$bare_nuclei <- as.integer(imputed_df_mean$bare_nuclei)\n",
    "\n",
    "# Confirm that data has been replaced\n",
    "imputed_df_mean %>% filter(bare_nuclei == '?') %>% nrow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Part 2\n",
    "In part 2 of question 14.1, I am going to impute the missing values using regression. From the lecture notes, this method will likely be more accurate than imputation through a mean, which I will analyze in part 4. To build the model, I will use bare_nuclei as the outcome variable, and the remaining columns as predictors. The training data set I will use includes data where bare_nuclei is not missing, and the test set will be the dataset with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "683"
      ],
      "text/latex": [
       "683"
      ],
      "text/markdown": [
       "683"
      ],
      "text/plain": [
       "[1] 683"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create training data set\n",
    "training <- df %>%\n",
    "    filter(bare_nuclei != '?')\n",
    "\n",
    "# Create test data set, split by predictors and outcome\n",
    "test_predictors <- missing_df %>%\n",
    "    select(-bare_nuclei)\n",
    "test_outcome <- missing_df %>%\n",
    "    select(bare_nuclei)\n",
    "\n",
    "# Print data lengths\n",
    "nrow(training)\n",
    "nrow(test_predictors)\n",
    "nrow(test_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With my data split by training and test sets, this next code block trains and evaluates a basic linear regression model using all of the data available. You can see from the model output that the RSquared value is 0.2792. To avoid over-fitting the data, I then built a second model based on the output P-Values from model 1. You can see that marginal_adhesion, normal_nucleoli, and class are the only significant predictors, so I built model 2 with this values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = as.integer(bare_nuclei) ~ ., data = training)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.8154 -0.5699 -0.4230 -0.2522  7.4785 \n",
       "\n",
       "Coefficients:\n",
       "                              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)                  3.336e-01  3.210e-01   1.039 0.299052    \n",
       "code_number                 -2.602e-08  1.142e-07  -0.228 0.819796    \n",
       "clump_thickness             -2.289e-02  3.645e-02  -0.628 0.530190    \n",
       "cell_size_uniformity         4.789e-02  6.195e-02   0.773 0.439790    \n",
       "cell_shape_uniformity        4.326e-02  6.027e-02   0.718 0.473185    \n",
       "marginal_adhesion           -1.282e-01  3.796e-02  -3.378 0.000771 ***\n",
       "single_epithelial_cell_size  1.255e-02  5.081e-02   0.247 0.805011    \n",
       "bland_chromatin             -2.836e-02  4.903e-02  -0.578 0.563202    \n",
       "normal_nucleoli              7.875e-02  3.651e-02   2.157 0.031379 *  \n",
       "mitosis                      6.559e-03  4.800e-02   0.137 0.891367    \n",
       "class                        1.077e+00  1.642e-01   6.557 1.09e-10 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.84 on 672 degrees of freedom\n",
       "Multiple R-squared:  0.2792,\tAdjusted R-squared:  0.2684 \n",
       "F-statistic: 26.03 on 10 and 672 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "# Train model\n",
    "lm_model <- lm(as.integer(bare_nuclei) ~ ., data = training)\n",
    "summary(lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = as.integer(bare_nuclei) ~ marginal_adhesion + normal_nucleoli + \n",
       "    class, data = training)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.6202 -0.5246 -0.4280 -0.3161  7.9230 \n",
       "\n",
       "Coefficients:\n",
       "                  Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)        0.12015    0.25120   0.478  0.63259    \n",
       "marginal_adhesion -0.11190    0.03533  -3.167  0.00161 ** \n",
       "normal_nucleoli    0.09656    0.03375   2.861  0.00436 ** \n",
       "class              1.16159    0.12163   9.551  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.836 on 679 degrees of freedom\n",
       "Multiple R-squared:  0.2751,\tAdjusted R-squared:  0.2719 \n",
       "F-statistic: 85.89 on 3 and 679 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_model2 <- lm(as.integer(bare_nuclei) ~ marginal_adhesion + \n",
    "                normal_nucleoli + \n",
    "                class, \n",
    "                data = training)\n",
    "summary(lm_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the output from model 2, the Rsquared value is 0.2751, which is only about 0.004 lower than the model which used every field as a predictor. Model 2 has considerably less complexity with a similar Rsquared, so I'm going to use model 2 to imput the missing values. In the code block below, I used the trained model 2 to predict the missing values in my test dataset created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>code_number</th><th scope=col>clump_thickness</th><th scope=col>cell_size_uniformity</th><th scope=col>cell_shape_uniformity</th><th scope=col>marginal_adhesion</th><th scope=col>single_epithelial_cell_size</th><th scope=col>bland_chromatin</th><th scope=col>normal_nucleoli</th><th scope=col>mitosis</th><th scope=col>class</th><th scope=col>bare_nuclei</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1057013 </td><td>8       </td><td>4       </td><td>5       </td><td>1       </td><td>2       </td><td>7       </td><td>3       </td><td>1       </td><td>4       </td><td>4.944304</td></tr>\n",
       "\t<tr><td>1096800 </td><td>6       </td><td>6       </td><td>6       </td><td>9       </td><td>6       </td><td>7       </td><td>8       </td><td>1       </td><td>2       </td><td>2.208742</td></tr>\n",
       "\t<tr><td>1183246 </td><td>1       </td><td>1       </td><td>1       </td><td>1       </td><td>1       </td><td>2       </td><td>1       </td><td>1       </td><td>2       </td><td>2.427998</td></tr>\n",
       "\t<tr><td>1184840 </td><td>1       </td><td>1       </td><td>3       </td><td>1       </td><td>2       </td><td>2       </td><td>1       </td><td>1       </td><td>2       </td><td>2.427998</td></tr>\n",
       "\t<tr><td>1193683 </td><td>1       </td><td>1       </td><td>2       </td><td>1       </td><td>3       </td><td>1       </td><td>1       </td><td>1       </td><td>2       </td><td>2.427998</td></tr>\n",
       "\t<tr><td>1197510 </td><td>5       </td><td>1       </td><td>1       </td><td>1       </td><td>2       </td><td>3       </td><td>1       </td><td>1       </td><td>2       </td><td>2.427998</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " code\\_number & clump\\_thickness & cell\\_size\\_uniformity & cell\\_shape\\_uniformity & marginal\\_adhesion & single\\_epithelial\\_cell\\_size & bland\\_chromatin & normal\\_nucleoli & mitosis & class & bare\\_nuclei\\\\\n",
       "\\hline\n",
       "\t 1057013  & 8        & 4        & 5        & 1        & 2        & 7        & 3        & 1        & 4        & 4.944304\\\\\n",
       "\t 1096800  & 6        & 6        & 6        & 9        & 6        & 7        & 8        & 1        & 2        & 2.208742\\\\\n",
       "\t 1183246  & 1        & 1        & 1        & 1        & 1        & 2        & 1        & 1        & 2        & 2.427998\\\\\n",
       "\t 1184840  & 1        & 1        & 3        & 1        & 2        & 2        & 1        & 1        & 2        & 2.427998\\\\\n",
       "\t 1193683  & 1        & 1        & 2        & 1        & 3        & 1        & 1        & 1        & 2        & 2.427998\\\\\n",
       "\t 1197510  & 5        & 1        & 1        & 1        & 2        & 3        & 1        & 1        & 2        & 2.427998\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| code_number | clump_thickness | cell_size_uniformity | cell_shape_uniformity | marginal_adhesion | single_epithelial_cell_size | bland_chromatin | normal_nucleoli | mitosis | class | bare_nuclei |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1057013  | 8        | 4        | 5        | 1        | 2        | 7        | 3        | 1        | 4        | 4.944304 |\n",
       "| 1096800  | 6        | 6        | 6        | 9        | 6        | 7        | 8        | 1        | 2        | 2.208742 |\n",
       "| 1183246  | 1        | 1        | 1        | 1        | 1        | 2        | 1        | 1        | 2        | 2.427998 |\n",
       "| 1184840  | 1        | 1        | 3        | 1        | 2        | 2        | 1        | 1        | 2        | 2.427998 |\n",
       "| 1193683  | 1        | 1        | 2        | 1        | 3        | 1        | 1        | 1        | 2        | 2.427998 |\n",
       "| 1197510  | 5        | 1        | 1        | 1        | 2        | 3        | 1        | 1        | 2        | 2.427998 |\n",
       "\n"
      ],
      "text/plain": [
       "  code_number clump_thickness cell_size_uniformity cell_shape_uniformity\n",
       "1 1057013     8               4                    5                    \n",
       "2 1096800     6               6                    6                    \n",
       "3 1183246     1               1                    1                    \n",
       "4 1184840     1               1                    3                    \n",
       "5 1193683     1               1                    2                    \n",
       "6 1197510     5               1                    1                    \n",
       "  marginal_adhesion single_epithelial_cell_size bland_chromatin normal_nucleoli\n",
       "1 1                 2                           7               3              \n",
       "2 9                 6                           7               8              \n",
       "3 1                 1                           2               1              \n",
       "4 1                 2                           2               1              \n",
       "5 1                 3                           1               1              \n",
       "6 1                 2                           3               1              \n",
       "  mitosis class bare_nuclei\n",
       "1 1       4     4.944304   \n",
       "2 1       2     2.208742   \n",
       "3 1       2     2.427998   \n",
       "4 1       2     2.427998   \n",
       "5 1       2     2.427998   \n",
       "6 1       2     2.427998   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use trained model to predict missing values of bare_nuclei in test data set\n",
    "preds <- predict(lm_model2, test_predictors)\n",
    "\n",
    "# Add predictions column to the test dataset\n",
    "test_predictors$bare_nuclei <- preds\n",
    "head(test_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "699"
      ],
      "text/latex": [
       "699"
      ],
      "text/markdown": [
       "699"
      ],
      "text/plain": [
       "[1] 699"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add test + predictions back into the original data set\n",
    "training$bare_nuclei <- as.integer(training$bare_nuclei)\n",
    "imputed_df_regression <- training %>%\n",
    "    bind_rows(test_predictors)\n",
    "\n",
    "# Test to make sure no missing values in this dataset\n",
    "imputed_df_regression %>% filter(bare_nuclei == '?') %>% nrow()\n",
    "nrow(imputed_df_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the RSquared value is relatively low at 0.2751, we really don't know the strength of this model in context. Thsi could actually be a strong RSquared depending on how many other factors may introduce variability into the data set. We will see in part 4 if this method produces better values than the other imputation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Part 3\n",
    "In part 3 of question 14.1, we are instructed to using regression with perturbation to impute the missing data points. This method is similar to the method used in part 2 in that we are using regression to calculate the missing values, however we are increasing the variability in the data by perturbing the predictors normally. From the lectures, this method may or may not produce more accurate predictions, but it does better mirror real life situations by representing a normal distribution in the data. In the steps below, I will use the Mice package to execute regression with perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " iter imp variable\n",
      "  1   1  bare_nuclei\n",
      "  2   1  bare_nuclei\n",
      "  3   1  bare_nuclei\n",
      "  4   1  bare_nuclei\n",
      "  5   1  bare_nuclei\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "699"
      ],
      "text/latex": [
       "699"
      ],
      "text/markdown": [
       "699"
      ],
      "text/plain": [
       "[1] 699"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import mice library\n",
    "library(mice)\n",
    "\n",
    "perturb_df <- df\n",
    "# Mice requires NA values vs. ? to work\n",
    "perturb_df$bare_nuclei[perturb_df$bare_nuclei == '?'] <- NA\n",
    "\n",
    "# Convert bare_nuclei to integer\n",
    "perturb_df$bare_nuclei <- as.integer(perturb_df$bare_nuclei)\n",
    "\n",
    "# Build model with perturbation\n",
    "perturb_model <- mice(perturb_df, method = \"norm.nob\", m = 1)\n",
    "\n",
    "# fill in missing values with predictions\n",
    "imputed_df_perturb <- complete(perturb_model)\n",
    "\n",
    "# print number of NAs - should be 0\n",
    "imputed_df_perturb %>% filter(is.na(bare_nuclei)) %>% nrow()\n",
    "nrow(imputed_df_perturb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block above, I trained the model using the function Mice. I used the method \"norm.nob\" which executes Linear regression ignoring model error. Additionally I set the m value = to 1 for the Number of multiple imputations. Mice has a built in function complete, which uses the regression model to predict the missing values in the data set. You can see from the output above that there are no missing values after running the code, and the dataset is the same length as the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Part 4\n",
    "In part 4 of question 14.1, I am going to take the output from the 3 methods of missing data imputation and use those as input into a support vector model. I am going to testeach of the datasets to see which one has the highest prediction accuracy, and is thus the best method of imputation. In the first steps below, I loaded the ksvm library, made sure the datatypes were correct, and then split all of the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "library(kernlab)\n",
    "\n",
    "# Fix data types\n",
    "imputed_df_mean$bare_nuclei <- as.integer(imputed_df_mean$bare_nuclei)\n",
    "imputed_df_regression$bare_nuclei <- as.integer(imputed_df_regression$bare_nuclei)\n",
    "imputed_df_perturb$bare_nuclei <- as.integer(imputed_df_perturb$bare_nuclei)\n",
    "\n",
    "# Create value for dividing data into train and test\n",
    "sample_size = floor(0.75*nrow(df))\n",
    "set.seed(123) # Set seed\n",
    "\n",
    "# Randomly identifies the rows equal to sample size\n",
    "train_ind = sample(seq_len(nrow(df)),size = sample_size)\n",
    "\n",
    "# Creates the training datasets with row numbers stored in train_ind\n",
    "train_mean = imputed_df_mean[train_ind,]\n",
    "train_regression = imputed_df_regression[train_ind,]\n",
    "train_perturb = imputed_df_perturb[train_ind,]\n",
    "\n",
    "# Creates the test datasets excluding the row numbers mentioned in train_ind\n",
    "test_mean = imputed_df_mean[-train_ind,]\n",
    "test_regression = imputed_df_regression[-train_ind,]\n",
    "test_perturb = imputed_df_perturb[-train_ind,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting\n",
    "each dataframe, I then ran each of them through a function that tests a range of critical values\n",
    "in the support vector machine function, builds a range of models, and then figures out what the\n",
    "highest prediction accuracy was. As can be seen in the output below, the method of missing\n",
    "value replacement that had the highest predictive accuracy when building a model was regression\n",
    "imputation (the second printed line) with a predictive accuracy of .97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting all of the data sets, I next trained 3 iterations of support vector models using each of the training data sets. I also tested multiple model argument values to find the highest prediction accuracy for each data set, and then output the final prediction accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.9485714\n",
      "[1] 0.9714286\n",
      "[1] 0.9428571\n"
     ]
    }
   ],
   "source": [
    "# KSVM function to evaluate multiple input values of K, \n",
    "# and output highest prediction accuracy\n",
    "set.seed(23)\n",
    "ksvm_impute_accuracy <- function(train, test) {\n",
    "    \n",
    "    # Create df to store prediction accuracricies for each C value\n",
    "    calibration_df <- data.frame(c_value = double(),\n",
    "                                prediction_accuracy = double())\n",
    "    \n",
    "    # Loop through C values\n",
    "    for (i in 1:15) {\n",
    "        # Create test model\n",
    "        trained_model <- ksvm(as.matrix(train[,1:10]), as.matrix(train[,11]),\n",
    "                            type = 'C-svc', C = 10**i, scale = TRUE)\n",
    "        \n",
    "        # Use trained model to output predictions\n",
    "        test_preds <- predict(trained_model, as.matrix(test[,1:10]))\n",
    "        \n",
    "        # Evaluate predictions\n",
    "        test_accuracy <- sum(test_preds == test[,11]) / nrow(test)\n",
    "        \n",
    "        # Store accuracy results for given c value\n",
    "        calibration_df <- rbind(calibration_df, c(10**i, test_accuracy))\n",
    "    }\n",
    "    \n",
    "    # Rename df cols\n",
    "    names(calibration_df) <- c('c_value', 'prediction_accuracy')\n",
    "    \n",
    "    # Output top prediction accuracy\n",
    "    print(max(calibration_df$prediction_accuracy))\n",
    "}\n",
    "\n",
    "ksvm_impute_accuracy(train_mean, test_mean)\n",
    "ksvm_impute_accuracy(train_regression, test_regression)\n",
    "ksvm_impute_accuracy(train_perturb, test_perturb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output from each of the KSVM models, Regression is the most accurate model with a final prediction accuracy of 0.971. Mean imputation came in second place with 0.948, and regression with perturbation in a close 3rd with 0.942. All seem to be relatively good methods of replacing missing values, with regression performing the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15.1\n",
    "Describe a situation or problem from your job, everyday life, current events, etc., for which optimization\n",
    "would be appropriate. What data would you need? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A situation from one of my other classes in the OMSA program for which optimization is appropriate is my group project in CSE 6242. We are looking at a sentiment analysis of every presidential speech going back to George Washington, and trying to use those metrics as predictors for approval ratings. Approval ratings weren't widely collected until 1940 with Franklin D. Roosevelt, so I would want to use imputation to back-fill the missing data for presidents before 1940. Admittedly, this is a lot of data to fill in, so it would make sense to try a few different ways. First, I would build the model with the data I have, so only looking at data from 1940 to present. Next, I would try all 3 methods of imputation across the entire data set, and finally, I would try and group presidents by similar sentiment scores and then find the average ratings within those groupings for imputation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
